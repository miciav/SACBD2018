\section{Introduction}

EW-Shopp aims to support e-commerce, retail and marketing industries in improving their efficiency and competitiveness through providing the ability to perform predictive and prescriptive analytics over integrated and enriched large data sets through the use of open and flexible solutions. 
This document is intended to be the first step towards the construction of the EW-Shopp ecosystem, a platform that seeks to significantly reduce integration time and to improve the quality of analytics by providing cutting-edge tools and access to data as a service, with particular reference to weather and event information.  


For some years now we have been witnessing the flourishing and reinforcement of Big Data methodologies in academia but especially in industry. 
This success can be partly explained by the promise of Big Data supporters to define and deliver more accurate and efficient data-driven decision-making processes.
This is not the only asset, though, but it is what we are most interested in highlighting within the EW-Shopp project. 

The term "Data Analytics" is too often used to define a generic data driven decision process and therefore covers heterogeneous activities such as cleaning, linking, enrichment/extension, training and application of analytic models, up to business intelligence and visualization. 
In this document, we propose a platform from its components and their relationships. We present a reference architecture obtained from a rigorous process of requirements elicitation that took into account both literature and best practices as well as the needs expressed by involved stakeholders. 
In that particular document, not only the functional requirements associated with business cases (the implementation and reporting of which in marketed services is one of the core aspects of the project) have been collected and refined, but also the development guidelines based on lean methodology [2] have been defined. In particular, the build-measure-learn feedback loop is also presented. 
In a nutshell, the methodology envisions for each pilot a starting phase with Minimum Viable Product (MVP) meant to reduce the time-to-market. The MVP is going to be enriched as the project progresses and the vision matures. Pilots are therefore seen as playgrounds for experimenting approaches and technologies that eventually will be included in the final marketed services. 


At the time this document is written, we have designed a unified, complete and well-founded reference architecture. The declared objective is to provide a point of reference that will remain as steady as possible for the entire duration of the project and that can thus lead its evolution on the basis of a solid and agreed basis. 

To do this, as we will see, we started from the functional requirements trying to read in them the answers to the architectural questions that we asked ourselves.  It was immediately evident, however, that these requirements were not sufficient to define a modern, efficient, responsive and scalable platform. As a consortium, we have therefore decided to undertake an in-depth study of the problems that we want to tackle. Some results of such teamwork are detailed here.  

With the work the consortium has done on component design, the processes and outcomes of which are described in this document, we aim to achieve the following two objectives:
\begin{itemize}
    \item Define a reference architecture. This deliverable provides a reference architecture that aims at being general and flexible enough to be successful applied in the pilots. The architecture describes the core components and their relationships in terms of data flow. Moreover, it aims at setting a common language among the partners. To make this possible, we have referred to the pilot descriptions, the partnersâ€™ experience, and the best practices of the field of Big Data. Furthermore, the effort required to define precisely the pilots, especially in terms of processes, data flow and workflow, has spawned awareness in the consortium members about the complexity of the problem and the need of a common reference. Finally, it is important to note that defining a reference architecture does not conflict with the lean methodology as we describe the components according to their general functionality, without imposing specific solutions.
    \item Propose an initial implementation of the platform. This deliverable also provides an early stage implementation of the reference architecture.
\end{itemize}


This work is structured as follows. 
In Section \ref{sec:architecture} we present the reference architectures for Big Data as well as the main solutions for data wrangling, data analytics, business intelligence and reporting. 
The requirements that have guided the definition of our reference architecture are presented and discussed in Section 3. 
Finally, Section~\ref{sec:conclusions} concludes the document. 








